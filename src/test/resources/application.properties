# Grop API Configuration
quarkus.langchain4j.openai.base-url=https://api.groq.com/openai/v1/
quarkus.langchain4j.openai.api-key=${GROQ_API_KEY}

# Model Selection - Use a current active model
# Choice 1: llama-3.3-70b-versatile (Large, powerful)
# Choice 2: llama-3.1-8b-instant (Extremely fast)
# Choice 3: mixtral-8x7b-32768
quarkus.langchain4j.openai.chat-model.model-name=llama-3.3-70b-versatile

quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true
quarkus.langchain4j.openai.timeout=60s